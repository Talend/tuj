//SET hbase.cluster.distributed=true;
SET hbase.zookeeper.quorum=mapr-desktop;
SET hbase.zookeeper.property.clientPort=5181;

CREATE TABLE hive_hbase_test5 (id int, name string) 
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
TBLPROPERTIES ("hbase.table.name" = "hbase_test5");

CREATE TABLE IF NOT EXISTS source3 (id INT, name STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LOCATION '/user/talend2/tables/source3';

LOAD DATA INPATH 'hdfs://talend-hdp-bimota:8020/user/talend2/in.csv' OVERWRITE INTO TABLE source3;

INSERT OVERWRITE TABLE hive_hbase_test5 SELECT * FROM source3;

CREATE TABLE IF NOT EXISTS target (id INT, name STRING) PARTITIONED BY(city STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LOCATION '/user/talend2/tables/target';

INSERT INTO TABLE target PARTITION(city='Shunyi') SELECT * FROM hive_hbase_test5;
INSERT OVERWRITE TABLE target PARTITION(city='Shunyi') SELECT * FROM hive_hbase_test5;

INSERT INTO TABLE target PARTITION(city='Shunyi') SELECT id,name FROM hive_hbase_test5;
INSERT OVERWRITE TABLE target PARTITION(city='Shunyi') SELECT id,name FROM hive_hbase_test5;

SELECT s3.id,s3.name,s.key,s.value FROM source3 s3 JOIN source s ON (s3.id = s.key);

CREATE TABLE hive_hbase_test6 (id int, name string) PARTITIONED BY(city STRING) 
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,cf1:val")
TBLPROPERTIES ("hbase.table.name" = "hbase_test6");

INSERT OVERWRITE TABLE hive_hbase_test6 PARTITION(city='Shunyi') SELECT * FROM source3;

INSERT OVERWRITE TABLE hive_hbase_test7 SELECT s3.id,s3.name FROM source3 s3 JOIN source s ON (s3.id = s.key);

add jar /usr/lib/hive/lib/protobuf-java-2.4.0a.jar;
add jar /usr/lib/hive/lib/zookeeper-3.4.5.21.jar;
add jar /usr/lib/hive/lib/hbase-0.94.2.21.jar;
add jar /usr/lib/hive/lib/hive-hbase-handler-0.10.0.21.jar;

select * from hive_hbase_test5;

hive_hbase_test5

<property>     
  <name>hive.aux.jars.path</name>     
  <value>file:///usr/lib/hive/lib/hive-hbase-handler-0.10.0.21.jar,file:///usr/lib/hive/lib/hbase-0.94.2.21.jar,file:///usr/lib/hive/lib/zookeeper-3.4.5.21.jar</value>     
</property>  

//HDP 1.0
add jar /usr/share/hbase/lib/protobuf-java-2.4.0a.jar;
add jar /usr/share/hbase/lib/zookeeper-3.4.2.jar;
add jar /usr/share/hbase/hbase-0.92.0.jar;
add jar /usr/share/hcatalog/lib/hive-hbase-handler-0.4.0.jar;

//HDP (1.1) TUJ Context
add jar /usr/lib/hbase/lib/protobuf-java-2.4.0a.jar;
add jar /usr/lib/zookeeper/zookeeper-3.3.4.14.jar;
add jar /usr/lib/hbase/hbase-0.92.1.14.jar;
add jar /usr/lib/hive/lib/hive-hbase-handler-0.9.0.14.jar;

//CDH4 1.0
add jar /usr/lib/hbase/lib/protobuf-java-2.4.0a.jar;
add jar /usr/lib/zookeeper/zookeeper-3.4.3-cdh4.0.0.jar;
add jar /usr/lib/hbase/hbase-0.92.1-cdh4.0.0-security.jar;
add jar /usr/lib/hive/lib/hive-hbase-handler-0.8.1-cdh4.0.0.jar;

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

HBASE PIG:

register /usr/lib/hbase/hbase-0.94.2.21.jar
register /usr/lib/zookeeper/zookeeper-3.4.5.21.jar
register /usr/lib/hbase/lib/guava-11.0.2.jar

register /usr/lib/pig/lib/protobuf-java-2.4.0a.jar

A = load '/user/talend2/in.csv' using PigStorage(':')  AS (id:chararray, name:chararray);
B = load '/user/talend2/in.csv' using PigStorage(':')  AS (id:chararray, sex:chararray);
C = load '/user/talend2/in.csv' using PigStorage(':')  AS (id:chararray, age:chararray);
STORE A INTO 'hbase://test4' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:b');

A = load 'hbase://test' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:a cf:b cf:c','-loadKey true -limit 2') AS (id:chararray, a:chararray, b:chararray, c:chararray);
STORE A INTO 'hbase://test4' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:a1 cf:b1 cf:c1');

A = load 'hbase://test' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:a cf:b cf:c','-limit 2') AS (id:chararray, a:chararray, b:chararray, c:chararray);
STORE A INTO 'hbase://test4' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:a2 cf:b2 cf:c2');

store A into 'hbase://test4' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:a cf:b cf:c','loadKey true');

tPigLoad_1_RESULT = LOAD 'hbase://test' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:key cf:name','-loadKey true -limit 5 -lt row5') AS (rowkey:chararray, key:chararray, name:chararray);
tPigLoad_1_TMP_RESULT = FOREACH tPigLoad_1_RESULT GENERATE $1,$0,$1,$2;
STORE tPigLoad_1_TMP_RESULT INTO 'hbase://test7' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:rowkey cf:key cf:name');

A = load 'test' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:id cf:name') AS (id:chararray, name:chararray);
STORE A INTO '/user/talend2/out' using PigStorage(';');